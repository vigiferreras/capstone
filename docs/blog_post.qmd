---
title: "The Curse of The Grammys"
subtitle: "Spring 2024"
author: "Virginia Ferreras"
bibliography: references.bib
number-sections: false
format:
  html:
    theme: default
    rendering: embed-resources
    code-fold: true
    code-tools: true
    toc: true
  pdf: default
execute: 
  echo: false
jupyter: python3
---



![Source: Grammys.com](grammy_pic.jpeg)


I am going to list five very different artists and I want you to try and figure out what these artists have in common: Evanescence, Cyndi Lauper, Victoria Monet, Carrie Underwood, and Arrested Development. This is a very challenging task but here is a hint: they have all won a similar music award. If your answer is that they all won a Grammy, you are partially correct. These five artists are all recipients of the Grammy’s Best New Artist Award. 

Presented by the Recording Academy of the United States, the Grammy Awards show is one of the most prestigious award shows in the music industry. With over 90 awards recognizing the successes and talents of many individuals within the music industry, the Best New Artist award presented during the show draws a lot of attention due to the fact that it shines light towards talented new artists.

Aside from the excitement associated with this ceremony and the awards given out, there is a dark mystery that is tied to the Grammys: the Best New Artist Curse. The curse has been a subject of debate for years [@curse_article], stating that winners of this award are cursed with a short-lived career, marked by a decline in successes, achievements, and relevancy. As an avid music listener and fan myself, I have been intrigued by this curse and have always questioned its validity. Do the successes of artists truly decrease after winning this award? Is there a way to predict the success trajectory of future Best New Artist winners? 

To answer these questions I will be utilizing my data science knowledge and skills to analyze the post-award musical achievements of these artists and explore the potential for predicting an artist’s success. Without further ado, follow me as I combine music and data to dissect the mysteries of the Best New Artist curse. 

```{python}

# libraries used

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import plotly.graph_objs as go
import plotly.offline as py
import plotly.express as px


from wordcloud import WordCloud

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import Pipeline
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import cross_val_score
```

# Data Collection 
Every Data Science project needs its data, therefore I went ahead and collected as much data as I could find publicly to investigate this curse. I went through a meticulous data collection process utilizing various methods:

## Manual Data Entry
Beginning with the focal point of the project, I used the Grammy’s official website to compile a list of Best New Artist winners spanning from 1980 to 2022 [@grammys_info]. To assess post-award activity, I used the IMDb.com website to collect information about music award wins and nominations from the MTV Video Music Awards [@vmas_info] and the American Music Awards [@amas_info], as well as the Recording Industry Association of America (RIAA) website to gather data regarding gold, platinum, and diamond awards [@riaa_info]. For all of these manual collections, I entered the data into a separate spreadsheet for each unique award. 

I also manually collect details about the winners, including birth location, gender, and membership in music groups, primarily from Wikipedia [@wikipedia].

## Web Scraping
To further investigate post-award activity, I employed web-scraping techniques[@web_scraping_help, @web_scraping_help2] to collect Billboard Hot 100s data [@billbord_chart]. Collecting this data will allow us to look for how many chart appearances these award recipients have had post-award win. 

## Spotify API
Utilizing Spotify’s API, I collected data on the genres associated with each Best New Artist winner [@spotify_api]. 

These methods allowed me to collect a wide variety of data that can be used for future analysis. Please keep in mind that there are potential limitations that arise from this collected data, particularly in regards to the reliability of the data collected from public sources. 

# Data Cleaning
``` {python}
#| output: false

best_new = pd.read_csv('/Users/virginiaferreras/Desktop/capstone/data/best_new2.csv')
best_new_df = pd.DataFrame(best_new)
best_new_df.head()

# checking dimension of the dataset
best_new_df.shape

# Cleaning the Best New Artist dataset

# will be focusing on artists starting from 1985
# dropping the first five columns (1980-1984 winners)
best_new_df = best_new_df.drop(best_new_df.index[:5])

# updating the award_date column data type
best_new_df['award_date'] = pd.to_datetime(best_new_df['award_date'])

# checking for missing values
best_new_df.isna().sum()

# Cleaing the Billboard Hot 100s dataset

hot100_read = pd.read_csv('/Users/virginiaferreras/Desktop/capstone/data/chart_data.csv')
hot100_df = pd.DataFrame(hot100_read)

# checking dimension of df
hot100_df.shape 

# dropping peak position
hot100_df = hot100_df.drop('peak_position', axis = 'columns')


# adjusting the data type of the week_of column
hot100_df['week_of'] = pd.to_datetime(hot100_df['week_of'])

# checking the number of missing values
hot100_df.isna().sum()

# splitting the columns 

# creating a copy of the original hot 100s dataset
hot100_split = hot100_df

# ----------------------------
# START CITATION 
# links below were used to help me with the regular expressions

# https://saturncloud.io/blog/how-to-split-pandas-dataframe-column-values-in-python/#:~:text=Splitting%20Pandas%20dataframe%20column%20values%20can%20be%20done%20using%20the,string%2C%20or%20a%20regular%20expression.
# https://note.nkmk.me/en/python-split-rsplit-splitlines-re/
# https://www.dataquest.io/blog/regex-cheatsheet/

# defining the diferrent variations of the word "featuring" 
# This variable will be used as the seperator to split a string of artists
# spliting the column
# creating a separate df to house the separated columns
# the delimiter in this case are all variations of 'featuring'
hot100_split[['main_artist', 'featured_artists']] = hot100_split['artist_name'].str.split(r'\s+(?:Featuring|feat|ft|Feat|Ft|featuring)\s+', n = 1, expand = True)
# END CITATION 
# ----------------------------
# START CITATION 
# links below were used to help me with the regular expressions

# https://saturncloud.io/blog/how-to-split-pandas-dataframe-column-values-in-python/#:~:text=Splitting%20Pandas%20dataframe%20column%20values%20can%20be%20done%20using%20the,string%2C%20or%20a%20regular%20expression.
# https://note.nkmk.me/en/python-split-rsplit-splitlines-re/
# https://www.dataquest.io/blog/regex-cheatsheet/

# new variable to define the diferrent variations of the word "and"
# includes the exceptions of specific words from groups that shouldn't be split
# splitting the 'main_artist' column based on the regular expression pattern 

split_main_artists = hot100_split['main_artist'].str.split(r'(?i)\s+(?:&(?! The Range| The Blowfish| Ryan Lewis)|and(?! The Range| The Blowfish| Ryan Lewis))\s+', expand = True)

# renaming the split columns

# creating empty lists to hold the column names for the split columns
col_headers = []

# iterating through the split columns
for i in range(split_main_artists.shape[1]): 
    
    # creating header
    header = f'main_artist_{i + 1}'
    
    #appending to empty list
    col_headers.append(header)

# assigning the new column headers to the split main artists df 
split_main_artists.columns = col_headers

# concatenating the split columns with the original DataFrame
# creating a new df to avoid confusion and record each change made
hot100_split2 = pd.concat([hot100_split, split_main_artists], axis = 1)
# END CITATION 
# ----------------------------
# START CITATION 
# link/s below were used to help me generate the following code (reordering columns)

# https://www.geeksforgeeks.org/change-the-order-of-a-pandas-dataframe-columns-in-python/

# dropping artist_name and main_artist columns
hot100_split2 = hot100_split2.drop(['artist_name', 'main_artist'], axis = 1)

# reordering the columns
hot100_split2 = hot100_split2.iloc[:, [0,1,2,4,5,6,3]]
# END CITATION 
# ----------------------------

# START CITATION 

# links below were used to help me generate the following code (splitting columns, regular expressions)

# https://saturncloud.io/blog/how-to-split-pandas-dataframe-column-values-in-python/#:~:text=Splitting%20Pandas%20dataframe%20column%20values%20can%20be%20done%20using%20the,string%2C%20or%20a%20regular%20expression.
# https://note.nkmk.me/en/python-split-rsplit-splitlines-re/
# https://www.dataquest.io/blog/regex-cheatsheet/

# splitting the featured_artists column based on regular expression pattern 
split_artists = hot100_split2['featured_artists'].str.split(r'\s+(?:&|and|And|,)\s+', expand = True)

# renaming the split columns

# creating empty lists to hold the column names for the split columns
col_headers = []

# iterating through the split columns
for i in range(split_artists.shape[1]): 
    
    # creating header
    header = f'featured_artist_{i + 1}'
    
    #appending to empty list
    col_headers.append(header)

# assigning the new column headers to the split main artists df 
split_artists.columns = col_headers

# concatenating the split columns with the previous split dataset 
# creating a new df to avoid confusion and record each change made
hot100_split3 = pd.concat([hot100_split2, split_artists], axis = 1)
#END CITATION
# ----------------------------
# START CITATION 

# links below were used to help me generate the following code (splitting columns, regular expressions)

# https://saturncloud.io/blog/how-to-split-pandas-dataframe-column-values-in-python/#:~:text=Splitting%20Pandas%20dataframe%20column%20values%20can%20be%20done%20using%20the,string%2C%20or%20a%20regular%20expression.

# splitting the featured_artist_1 column based on the comma separator
split_feats = hot100_split3['featured_artist_1'].str.split(',', expand = True)

# renaming the split columns

# creating empty lists to hold the column names for the split columns
col_headers = []

# iterating through the split columns
for i in range(split_feats.shape[1]): 
    
    # creating header 
    # note that since we already have the first 3 featured artists, the headers be feat_artist number 4 and on
    header = f'featured_artist_{i + 4}'
    
    #appending to empty list
    col_headers.append(header)

# assigning the new column headers to the split main artists df 
split_feats.columns = col_headers


# concatenating the split columns with the previous split dataset
# creating a new df to avoid confusion and record each change made
hot100_split4 = pd.concat([hot100_split3, split_feats], axis = 1)

#END CITATION
# ----------------------------

# dropping the featured_artist_1 column
hot100_split4 = hot100_split4.drop('featured_artist_1', axis = 'columns')

# ----------------------------

# START CITATION 

# link/s below were used to help me generate the following code (reordering columns)

# https://www.geeksforgeeks.org/change-the-order-of-a-pandas-dataframe-columns-in-python/

# reordering the columns for easier readability
hot100_split4 = hot100_split4.iloc[:, [0,1,2,3,
                                       4,5,8,9,
                                       10,11,6,7,
                                       12,13,14,15]]


# renaming column headers
hot100_split4.columns = ['chart_week', 'rank', 'song_title', 'main_artist_1', 'main_artist_2', 'main_artist_3',
                       'featured_artist_1', 'featured_artist_2', 'featured_artist_3', 'featured_artist_4', 
                        'featured_artist_5', 'featured_artist_6', 'featured_artist_7', 'featured_artist_8',
                       'featured_artist_9', 'featured_artist_10']

#END CITATION
# ----------------------------

# applying the strip() function to values from the third column to the last column
for col in hot100_split4.iloc[:, 2:]:
    hot100_split4[col] = hot100_split4[col].str.strip()

# ----------------------------
# START CITATION 
# link/s below were used to help me generate the following code (selecting based on multiple conditions)

# https://note.nkmk.me/en/python-pandas-multiple-conditions/

# Best New Award Winners
selected_artists = best_new_df['artist'].unique()

# Filtering the hot100_split4 DataFrame to include rows where any of the selected artists appear
filtered_hot100 = hot100_split4[
    (hot100_split4['main_artist_1'].isin(selected_artists)) |
    (hot100_split4['main_artist_2'].isin(selected_artists)) |
    (hot100_split4['main_artist_3'].isin(selected_artists)) |
    (hot100_split4['featured_artist_1'].isin(selected_artists)) |
    (hot100_split4['featured_artist_2'].isin(selected_artists)) |
    (hot100_split4['featured_artist_3'].isin(selected_artists)) |
    (hot100_split4['featured_artist_4'].isin(selected_artists)) |
    (hot100_split4['featured_artist_5'].isin(selected_artists)) |
    (hot100_split4['featured_artist_6'].isin(selected_artists)) |
    (hot100_split4['featured_artist_7'].isin(selected_artists)) |
    (hot100_split4['featured_artist_8'].isin(selected_artists)) |
    (hot100_split4['featured_artist_9'].isin(selected_artists)) |
    (hot100_split4['featured_artist_10'].isin(selected_artists))
]

#END CITATION
# ----------------------------

# filtered_hot100s copy
filtered_hot100_copy = filtered_hot100
# ----------------------------
# START CITATION 

# link/s below were used to help me generate the following code (.values(), .at())

# https://www.geeksforgeeks.org/python-pandas-dataframe-values/
# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at.html

# making new columns for main_artist and featured_artist
filtered_hot100_copy['main_artist'] = 'no' # default = no 
filtered_hot100_copy['featured_artist'] = 'no' # default = no 
filtered_hot100_copy['artist'] = None  # default = None

# setting default values for new columns
filtered_hot100_copy['main_artist'] = 'no'
filtered_hot100_copy['featured_artist'] = 'no'
filtered_hot100_copy['artist'] = 'Name Not Found'

# iterating through EACH ROW in filtered_hot100_copy
for index, row in filtered_hot100_copy.iterrows():
    
    # iterating through EACH ARTIST in the SELECT ARTIST LIST
    for artist in selected_artists:
        
        if (artist in row.values[3:6]): # looking at the three main artist columns
            filtered_hot100_copy.at[index, 'main_artist'] = 'yes' # marking yes for main artist column at that specific row
            
        else: # if the artist was not found in the main artist column then they are a featured artist for this instance 
            filtered_hot100_copy.at[index, 'featured_artist'] = 'no' # marking yes for featured artist column at that specific row
            
        # assigning the name of the searched artists to the specific row and artist name column
        for artist in selected_artists:
            if artist in row.values[3:]: # searching artist name in the the df from the third column on
                filtered_hot100_copy.at[index, 'artist'] = artist # if found, assign the name to the artist name column 
                break # stop searching for artist        

#END CITATION
# ----------------------------

# reordering the columns 
filtered_hot100_copy = filtered_hot100_copy.iloc[:, [18,0,1,2,16,17]]

# creating boxplot
plt.figure(figsize=(8, 6))
sns.boxplot(data=filtered_hot100_copy, x='rank', orient='h', linewidth=2, color='lavender')
plt.title("Box Plot For Hot 100's Rank Column")
plt.ylabel('Rank')

# Cleaning the Artists Genre dataset 

artist_genres = pd.read_csv('/Users/virginiaferreras/Desktop/capstone/data/artist_general_info.csv')
artist_genres_df = pd.DataFrame(artist_genres)

# checking the dimenesion of the df
artist_genres_df.shape

# similar to the best_new_df, will be dropping the first five rows
artist_genres_df = artist_genres_df.drop(artist_genres_df.index[:5])
artist_genres_df = artist_genres_df.reset_index()

# dropping the three unneccesary columns
artist_genres_df = artist_genres_df.drop(['followers', 'popularity', 'index'], axis = 'columns')

# removing the brackets using string slicing 
artist_genres_df['genre'] = artist_genres_df['genre'].str[1:-1]

# removing the quotations
artist_genres_df['genre'] = artist_genres_df['genre'].str.replace("'", "")

# Cleaning the MTV Video Music Awards Dataset

vmas_awards = pd.read_csv('/Users/virginiaferreras/Desktop/capstone/data/vmas_winners_nominees2.csv')
vmas_awards_df = pd.DataFrame(vmas_awards)

# making copy of the original vmas_awards_df
vmas_copy = vmas_awards_df

# ----------------------------
# START CITATION 

# link/s below were used to help me generate the following code (splitting columns and regular expressions)

# https://saturncloud.io/blog/how-to-split-pandas-dataframe-column-values-in-python/#:~:text=Splitting%20Pandas%20dataframe%20column%20values%20can%20be%20done%20using%20the,string%2C%20or%20a%20regular%20expression.
# https://www.dataquest.io/blog/regex-cheatsheet/
# https://note.nkmk.me/en/python-split-rsplit-splitlines-re/

# splitting the artist_name column by the word feature (and its variations)
vmas_copy[['main_artist', 'featured_artists']] = vmas_copy['artist_name'].str.split(r'\s+(?:Feat.|feat.|Feat|feat)\s+', n = 1, expand = True)

# END CITATION
# -----------------------
# ----------------------------
# START CITATION 

# link/s below were used to help me generate the following code (splitting columns and regular expressions)

# https://saturncloud.io/blog/how-to-split-pandas-dataframe-column-values-in-python/#:~:text=Splitting%20Pandas%20dataframe%20column%20values%20can%20be%20done%20using%20the,string%2C%20or%20a%20regular%20expression.
# https://www.dataquest.io/blog/regex-cheatsheet/
# https://note.nkmk.me/en/python-split-rsplit-splitlines-re/

# splitting the main artists column by commas with the exception of Tyler, The Creator
vmas_split2 = vmas_copy['main_artist'].str.split(r'(?<!Tyler),\s*', expand = True)

# naming the column headers

# creating empty lists to hold the column names for the split columns
col_headers = []

# iterating through the split columns
for i in range(vmas_split2.shape[1]): 
    
    # creating header
    header = f'main_artist_{i + 1}'
    
    #appending to empty list
    col_headers.append(header)

# assignign the new column headers to the vmas_split2 df 
vmas_split2.columns = col_headers

# concatenating the split columns with the original df
vmas_copy = pd.concat([vmas_copy, vmas_split2], axis=1)

#resetting index
vmas_copy.reset_index(drop=True, inplace=True)

# END CITATION
# ----------------------------
# ----------------------------
# START CITATION 
# link/s below were used to help me generate the following code (splitting columns and regular expressions)

# https://saturncloud.io/blog/how-to-split-pandas-dataframe-column-values-in-python/#:~:text=Splitting%20Pandas%20dataframe%20column%20values%20can%20be%20done%20using%20the,string%2C%20or%20a%20regular%20expression.
# https://www.dataquest.io/blog/regex-cheatsheet/
# https://note.nkmk.me/en/python-split-rsplit-splitlines-re/

# splitting the featured artist column by commas
vmas_split3 = vmas_copy['featured_artists'].str.split(',', expand = True)

# naming the column headers

# creating empty lists to hold the column names for the split columns
col_headers = []

# iterating through the split columns
for i in range(vmas_split3.shape[1]): 
    
    # creating header
    header = f'featured_artist_{i+1}'
    
    #appending to empty list
    col_headers.append(header)

# assigning the new column headers to the vmas_split3 df 
vmas_split3.columns = col_headers

# concatenate the split columns with the original df
vmas_copy = pd.concat([vmas_copy, vmas_split3], axis=1)

# END CITATION
# ----------------------------

# dropping the three nnnecessary columns
vmas_copy = vmas_copy.drop(['artist_name', 'featured_artists', 'main_artist'], axis = 'columns')

# ----------------------------
# START CITATION 
# link/s below were used to help me generate the following code (striping whitespace)

# https://www.geeksforgeeks.org/pandas-strip-whitespace-from-entire-dataframe/
# removing the possible white spaces the strings have from splitting
for col in vmas_copy.iloc[:, 3:]:
    vmas_copy[col] = vmas_copy[col].str.strip()

# END CITATION
# ----------------------------
# ----------------------------
# START CITATION 
# link/s below were used to help me generate the following code (selecting based on multiple conditions)

# https://note.nkmk.me/en/python-pandas-multiple-conditions/

# Best New Award Winners
selected_artists = best_new_df['artist'].unique()

# filtering the hot100_split4 DataFrame to include rows where any of the selected artists appear
filtered_vmas = vmas_copy[
    (vmas_copy['main_artist_1'].isin(selected_artists)) |
    (vmas_copy['main_artist_2'].isin(selected_artists)) |
    (vmas_copy['main_artist_3'].isin(selected_artists)) |
    (vmas_copy['main_artist_4'].isin(selected_artists)) |
    (vmas_copy['main_artist_5'].isin(selected_artists)) |
    (vmas_copy['featured_artist_1'].isin(selected_artists)) |
    (vmas_copy['featured_artist_2'].isin(selected_artists)) |
    (vmas_copy['featured_artist_3'].isin(selected_artists)) |
    (vmas_copy['featured_artist_4'].isin(selected_artists)) |
    (vmas_copy['featured_artist_5'].isin(selected_artists)) |
    (vmas_copy['featured_artist_6'].isin(selected_artists)) 
]
# END CITATION
# ----------------------------

# making a copy of the filtered vmas dataset 
filtered_vmas_copy = filtered_vmas

# ----------------------------
# START CITATION 

# link/s below were used to help me generate the following code (.at() and .values())

# https://www.geeksforgeeks.org/python-pandas-dataframe-values/
# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at.html

# setting default values for new columns
filtered_vmas_copy['main_artist'] = 'no'
filtered_vmas_copy['featured_artist'] = 'no'
filtered_vmas_copy['artist'] = 'Name Not Found'

# iterating through EACH ROW in filtered_vmas_copy
for index, row in filtered_vmas_copy.iterrows():
    
    # iterating through EACH ARTIST in the SELECTED ARTIST list
    for artist in selected_artists:
        
            if (artist in row.values[3:9]): # looking at the five main artist columns
                filtered_vmas_copy.at[index, 'main_artist'] = 'yes' # marking yes for main artist column at that specific 
            else: # if the artist was not found in the main artist column then they are a featured artist for this instance
                filtered_vmas_copy.at[index, 'featured_artist'] = 'yes' # marking yes for featured artist column at that specific row
    
    # assigning the name of the searched artists to the specific row and artist name column
    for artist in selected_artists:
        if artist in row.values[3:]: # searching artist name in the the df from the third column on
            filtered_vmas_copy.at[index, 'artist'] = artist # if found, assign the name to the artist name column 
            break  # stop searching

# END CITATION
# ----------------------------

# reordering the columns and excluding main/featured split columns
filtered_vmas_copy = filtered_vmas_copy.iloc[:, [16,0,1,2,14,15]]


filtered_vmas_copy['win'].unique()

# ----------------------------
# START CITATION 
# link/s below were used to help me generate the following code

# https://www.geeksforgeeks.org/pandas-strip-whitespace-from-entire-dataframe/ (stripping whitespace)

# stripping white spaces from win column
filtered_vmas_copy['win'] = filtered_vmas_copy['win'].str.strip()
# END CITATION 
# ----------------------------

filtered_vmas_copy['win'].unique()

# fixing the data type for the date column
filtered_vmas_copy['date'] = pd.to_datetime(filtered_vmas_copy['date'])


# Cleaning the American Music Awards Dataset
amas_awards = pd.read_csv('/Users/virginiaferreras/Desktop/capstone/data/ama_wins_nominees2.csv')
amas_awards_df = pd.DataFrame(amas_awards)

# checking the dimensions of the new df
amas_awards_df.shape

# copying the amas_awards_df
amas_copy = amas_awards_df

# ----------------------------
# START CITATION 
# link/s below were used to help me generate the following code 

# https://note.nkmk.me/en/python-split-rsplit-splitlines-re/ (splitting columns)

# splitting the artist name column by comma seperator
amas_split = amas_copy['artist_name'].str.split(',', expand = True)

# naming the columns
amas_split.columns = [f'artist_{i + 1}' for i in range(amas_split.shape[1])]

col_headers = []

# iterating through the split columns
for i in range(amas_split.shape[1]): 
    
    # creating header
    header = f'artist_{i + 1}'
    
    #appending to empty list
    col_headers.append(header)

# assigning the new column headers to the amas_split df 
amas_split.columns = col_headers

# concatenating the split columns with the original df
amas_copy = pd.concat([amas_copy, amas_split], axis=1)

# END CITATION
# ----------------------------

# dropping the artist_name column 
amas_copy = amas_copy.drop('artist_name', axis = 1)

# ----------------------------
# START CITATION 
# link/s below were used to help me generate the following code

# https://www.geeksforgeeks.org/pandas-strip-whitespace-from-entire-dataframe/ (stripping whitespace)

# removing the possible white spaces the strings have from splitting
for col in amas_copy.iloc[:, 3:]:
    amas_copy[col] = amas_copy[col].str.strip()
# END CITATION
# ----------------------------
# ----------------------------
# START CITATION 
# link/s below were used to help me generate the following code (selecting based on multiple conditions)

# https://note.nkmk.me/en/python-pandas-multiple-conditions/

# Best New Award Winners
selected_artists = best_new_df['artist'].unique()

# filtering the ama_copy DataFrame to include rows where any of the selected artists appear
filtered_amas = amas_copy[
    (amas_copy['artist_1'].isin(selected_artists)) |
    (amas_copy['artist_2'].isin(selected_artists)) |
    (amas_copy['artist_3'].isin(selected_artists)) |
    (amas_copy['artist_4'].isin(selected_artists)) |
    (amas_copy['artist_5'].isin(selected_artists)) |
    (amas_copy['artist_6'].isin(selected_artists))

]

# END CITATION
# ----------------------------

# making a copy of the filtered_amas df
filtered_amas_copy = filtered_amas

# ----------------------------
# START CITATION 
# link/s below were used to help me generate the following code (.at(), .value())

# https://www.geeksforgeeks.org/python-pandas-dataframe-values/
# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at.html


# setting default values for new column
filtered_amas_copy['artist'] = 'Name Not Found' 

# iterating thrugh EACH ROW in filtered_amas_copy
for index, row in filtered_amas_copy.iterrows():
    
    # iterating through EACH ARTIST in the SELECTED ARTIST list
    for artist in selected_artists:
        
        if artist in row.values[3:]: # searching artist name in the the df from the third column on
            filtered_amas_copy.at[index, 'artist'] = artist # if found, assign the name to the artist name column
            break  # stop searching 

# END CITATION
# ----------------------------

# reordering columns
filtered_amas_copy = filtered_amas_copy.iloc[:, [9,0,1,2]]


# changing the date data type to a datatime data type
filtered_amas_copy['date'] = pd.to_datetime(filtered_amas_copy['date'])

# stripping white spaces from win column
filtered_amas_copy['win'] = filtered_amas_copy['win'].str.strip()


# Cleaning Recording Industry Association of America (RIAA) Awards dataset

riaa_awards = pd.read_csv('/Users/virginiaferreras/Desktop/capstone/data/RIAA_awards.csv')
riaa_awards_df = pd.DataFrame(riaa_awards)

# making a copy of the riaa_awards_df
riaa_copy = riaa_awards_df

# ----------------------------
# START CITATION 
# link/s below were used to help me generate the following code (mapping the values to change df variable names)

# https://stackoverflow.com/questions/20250771/remap-values-in-pandas-column-with-a-dict-preserve-nans

# Changing months to number format

month_num = {
    'January': '01',
    'February': '02',
    'March': '03',
    'April': '04',
    'May': '05',
    'June': '06',
    'July': '07',
    'August': '08',
    'September': '09',
    'October': '10',
    'November': '11',
    'December': '12'
}

# mapping the award month to its respective number 
riaa_copy['award_month'] = riaa_copy['award_month'].map(month_num)
# END CITATION
# ----------------------------

# changing the data type for the award month column 
riaa_copy['award_month'] = pd.to_numeric(riaa_copy['award_month'])

# ----------------------------
# START CITATION 
# link/s below were used to help me generate the following code

# https://stackoverflow.com/questions/19377969/combine-two-columns-of-text-in-pandas-dataframe (concatenating columns)

#combining the month, day, year column to make one date column 

# concatenating the columns to create a new date column
riaa_copy['award_date'] = riaa_copy['award_year'].astype(str) + '-' + riaa_copy['award_month'].astype(str) + '-' + riaa_copy['award_day'].astype(str)

# converting the new date column to datetime format
riaa_copy['award_date'] = pd.to_datetime(riaa_copy['award_date'])

# dropping the original columns
riaa_copy = riaa_copy.drop(['award_year', 'award_month', 'award_day'], axis=1)
# END CITATION
# ----------------------------
# ----------------------------
# START CITATION 
# link/s below were used to help me generate the following code (regular expressions)

# https://www.dataquest.io/blog/regex-cheatsheet/
# https://stackoverflow.com/questions/22588316/pandas-applying-regex-to-replace-values

# replacing any occurrence of '[number]x Platinum' with 'Multi Platinum'
riaa_copy['award_type'] = riaa_copy['award_type'].str.replace(r'^(\d+)x\s*Platinum$', 'Multi Platinum', regex = True)

# replacing any occurrence of '[number]x Diamond' with 'Multi Diamond'
riaa_copy['award_type'] = riaa_copy['award_type'].str.replace(r'^(\d+)x\s*Diamond$', 'Multi Diamond', regex = True)
# END CITATION
# ----------------------------
# ----------------------------
# START CITATION 
# link/s below were used to help me generate the following code (get dummy variables and renaming columns)

# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html
# https://www.digitalocean.com/community/tutorials/pandas-rename-column-index

# making dummy columns for future analysis

# dummy_cols = ['award_type']
dummy_cols = ['award_type']
riaa_dummies = pd.get_dummies(riaa_copy[dummy_cols], prefix = dummy_cols)
dummy_riaa_df = pd.concat([riaa_copy, riaa_dummies], axis = 1)

# dropping the award type column
dummy_riaa_df = dummy_riaa_df.drop('award_type', axis = 'columns')


# changing headers
dummy_riaa_df = dummy_riaa_df.rename(columns = {'award_type_Gold': 'gold',
                                                'award_type_Platinum': 'platinum',
                                                'award_type_Diamond': 'diamond',
                                                'award_type_Multi Diamond': 'multi_diamond',
                                                'award_type_Multi Platinum': 'multi_platinum',})

# END CITATION
# ----------------------------

# stripping white spaces from artist column
dummy_riaa_df['artist'] = dummy_riaa_df['artist'].str.strip()

# Cleaning Artist Information dataset 

artist_info = pd.read_csv('/Users/virginiaferreras/Desktop/capstone/data/artist_info.csv')
artist_info_df = pd.DataFrame(artist_info)

# looking at the unique values for the gender column 
artist_info_df['gender'].unique()

# looking at the unique values for the music group column 
artist_info_df['music_group'].unique()

# fixing the gender column
artist_info_df['gender'] = artist_info_df['gender'].str.lower().str.strip()

# fixing the music group column
artist_info_df['music_group'] = artist_info_df['music_group'].str.lower().str.strip()

# checking again
artist_info_df['gender'].unique()

# checking again
artist_info_df['music_group'].unique()
```

With any data driven project, data preprocessing is a crucial step in creating your models and visualizations. For this project I went through each dataset and  performed the usual preprocessing techniques which included: 

- Changing data types: I had to adjust any date column on my datasets to be a date/time object rather than a categorical object

- Checking for Missing and Duplicate Values: Luckily, since I mainly collected the data manually and had full control over what data I was grabbing, I had no missing or duplicated values to worry about!
 
- Dropping unnecessary columns: After collecting the data, I had time between collecting it and creating my code to really think about the practicality some columns had towards my overall project. Therefore some columns were dropped during this stage.

- Removing white spaces, brackets, changing casing: Very typical grammar fixes

Now aside from the simple techniques, I did have to do a little more thinking and perform some complicated procedures. First and foremost, many songs that are featured on the charts or nominated for an award may have either more than one mian artist or more than one featured artist on the song. Since my project is focusing on the post-award win activity of each of the winners, I want to ensure I include every instance an artist is seen on a chart or award nomination, even if that means they are not the only artist on that song. Therefore, I had to split the artist columns on the Billboard Hot 100s, VMA, and AMA datasets in order to have each artist on a song be represented by their own column. After separating each of the main and featured artists, I went ahead and filtered the dataset to only include the instances where the Best New Artists winners were spotted and reduced to have two binary columns that verify whether the artist is a main artist or featured artist for this instance. The VMA and AMA dataset also had a column that included whether they won the award or not. 

The RIAA dataset also had me perform some extra steps to get it cleaned up. Aside from adjusting and combing the separated date columns, I also went ahead and renamed some of the award names. Any platinum or diamond award that has a value such as “2x, 3x, 4x, etc” in front of it was renamed to simply “multi-platinum” or “multi-diamond”. I did this so that it will be easier to visualize and understand. Furthermore, I created dummy variables for each of the awards types. 

Lastly the Artist Genre dataset also had some extra steps to I had to take care of during this stage. It should be well known that with the fast growth of music throughout the years, there has been an expansion of genres in the music world. In fact, many artists may be associated with more than one genre. This can be seen in the genre dataset, as the genre column contained lists of genres that each artist is associated with. Due to this, I went ahead and created dummy variables for each genre in the list. This will also help for future modeling. 

# Exploratory Data Analysis

## Patterns Among Best New Artist Winners

Before delving into the analysis of these winners' success, lets breifly examine the commonalities shared by these artists. Are there any noticable patterns among the features shared by Best New Artist winners?

```{python}

#| label: fig-gender_distribution
#| fig-cap: "Distribution of the Best New Artist winners by gender." 
#| echo: true

# counting the number of wins of each gender
gender_counts = artist_info_df['gender'].value_counts()

# ---------------------------
# START CITATION
# Code block below was learned from CMPS 240 class (Ramapo College of NJ)

# creating the  bar chart
plt.figure(figsize=(6, 4))

gender_counts.plot(kind='bar', color=['mediumpurple','lightskyblue','burlywood'])

plt.title('Distribution of Grammys Best New Artist Award by Gender', 
          fontsize = 15, 
          fontweight = 'bold')

plt.xlabel('Gender', fontsize = 12, 
           fontweight='bold')

plt.ylabel('Number of Awards', fontsize = 12, 
           fontweight='bold')

plt.xticks(rotation=0)
plt.tight_layout()

plt.show()
# END CITATION
```

```{python}

#| label: fig-group_distribution
#| fig-cap: "Distribution of the Best New Artist winners in music groups." 
#| echo: true

# counting the number of music groups
group_counts = artist_info_df['music_group'].value_counts()

# START CITATION
# Code block below was learned from CMPS 240 class (Ramapo College of NJ)

# creating the bar chart
plt.figure(figsize=(6, 4))

group_counts.plot(kind='bar', color=['firebrick', 'mediumblue'])

plt.title('Distribution of Music Groups', 
          fontsize = 15, 
          fontweight = 'bold')

plt.xlabel('Music Group', 
           fontsize = 12, 
           fontweight = 'bold')

plt.ylabel('Count', 
           fontsize = 12, 
           fontweight = 'bold')
plt.xticks(rotation=0) 
plt.tight_layout()

plt.show()
# END CITATION
```

According to the @fig-gender_distribution, it is evident that female artists dominate the Grammys' Best New Artist award, followed by male artists. The "both" catergory represents bands that includes memebrs of both genders. Similarly, @fig-group_distribution tells us that solo artists tend to win these awards over music groups. 

While this observation does not relate to my initial research question, it is interesting to note the patterns in who these winners tend to be. 


## Most Popular Genres Among Best New Artist Winners 
```{python}

#| label: fig-word_cloud
#| fig-cap: "Common genres associated with the Best New Artist winners" 
#| echo: true

# if you havent already, this package needs to be installed to create the work cloud
# pip install WordCloud

# creating word cloud to visualize genre popularity

# START CITATION 

# link/s below were used to help me generate the following code (replace text in string, .join)

# https://stackoverflow.com/questions/28986489/how-to-replace-text-in-a-string-column-of-a-pandas-dataframe
# https://www.programiz.com/python-programming/methods/string/join

# replacing any instance of hip hop with hip-hop. This will help keep the words connected
artist_genres_df['genre'] = artist_genres_df['genre'].str.replace('hip hop', 'hip-hop')

# combining the words in each genre string into a single genre string,
# example: canadian contemporary = canadiancontemporary; hip pop = hippop
# removing spaces, hyphensm and replacing "r&b" with "rhythmblues"
text_data = ' '.join(artist_genres_df['genre'].str.replace(' ', '').str.replace('-', '').str.replace('r&b', 'rhythmblues').str.replace(',', ' ').values)
# END CITATION
# -----------------------------
# -----------------------------
# START CITATION 
# link/s below were used to help me generate the following code (word cloud)

# https://www.datacamp.com/tutorial/wordcloud-python

# creating the wordcloud 
wordcloud = WordCloud(width = 800, 
                      height = 400, 
                      background_color = 'white', 
                      colormap = 'twilight', 
                      random_state = 30).generate(text_data)

# displaying word cloud
plt.figure(figsize = (8, 6))
plt.imshow(wordcloud, 
           interpolation = 'bilinear')
plt.axis('off')

plt.show()
# END CITATION

```

Next up, since each artist is associated with several different genres, I want to visualize the most common genres that are shared by these Best New Artist winners. While this information is not directly appicable to my research question, it is interesting to see what genres tend to dominant the Best New Artist award. Based on @fig-word_cloud, we can see that some of the most popular genres include: dance pop, pop, urban contemporary, new wave pop, and rhythm and blues (R&B). 

## Artist Activity Throughout the Years
In order to really investigate whether the success of an artist decreases after winning the Best New Artist award. I created two x-axis interactive timeline charts, one chart visualizes when each artist appeared on the Billboard Hot100s chart and the other chart visualizes when each artist won/were nominated for an award.

These timelines will allow us to view how active and relevant each artist was after winning their Best New Artist Award.

:::{.callout-tip}
## Tip: How to read the timelines
- Each line on the timeline represents a different artists
- The star represents when an artist won the Best New Artist award
- The purple dot in @fig-hot100s_timeline represents an instance when the artists appears on the Billboard Hot 100s chart
- The green dot in @fig-vma_ama represents when an artist won an award they were nominated for, and the orange dot represents when an artist was nominated for an award. 
:::

```{python}
#| output: false

# grouping the countries and counting the artists from that country

country_count = artist_info_df['birth_country'].value_counts()

country_count_df = pd.DataFrame(country_count)

country_count_df = country_count_df.reset_index()

artist_info_df['birth_country'].unique()
# ---------------------------
# START CITATION 

# link/s below were used to help me generate the following code (creating and customizing the bar char)

# https://python-graph-gallery.com/3-control-color-of-barplots/
# https://stackoverflow.com/questions/11264521/date-ticks-and-rotation

color = ['lightblue', 'blue', 'purple', 'red', 'orange', 'pink', 'green', 'yellow']

# Create bars
fig, ax = plt.subplots()
ax.bar(country_count_df['birth_country'], country_count_df['count'],
       color=color,
       linewidth=3)

ax.tick_params(axis='x', rotation=75)

plt.title('Best New Artist Grammy Winners by Country', 
          fontsize = 15, 
          fontweight = 'bold')

plt.xlabel('Country', 
           fontsize = 12, 
           fontweight = 'bold')

plt.ylabel('Count', 
           fontsize = 12, 
           fontweight = 'bold')

# END CITATION

```

```{python}

#| label: fig-vma_ama
#| fig-cap: "Timeline depicting when each Best New Artist won or was nominated for a MTV Video Music Award (VMA) or American Music Award (AMA) in relation to their Grammy Best New Artist win." 
#| warning: false

# ---------------------------
# START CITATION 
# link/s below were used to help me generate the following code ()

# (creating scatter plot) https://plotly.com/python/line-and-scatter/
# (add multiple traces in one plot) https://stackoverflow.com/questions/72349796/add-a-plotly-express-trace-to-a-graph-objects-go-figure-with-multiple-traces
# (plotly.go parameters) https://plotly.com/python-api-reference/generated/plotly.graph_objects.Scatter.html
# (Hover text) https://stackoverflow.com/questions/59057881/how-to-customize-hover-template-on-with-what-information-to-show
# (removign trace name) https://community.plotly.com/t/how-to-remove-the-trace0-and-trace-1-boxes-when-hovering-over-pie-charts-in-subplot/76302/2
# (date) https://plotly.github.io/plotly.py-docs/generated/plotly.graph_objects.Waterfall.html


# creating a plotly figure
fig = go.Figure()

# creating the scatter plot timeline 

# scatter points for Best New Artist Win
fig.add_trace(go.Scatter(x = best_new_df['award_date'], 
                         y = best_new_df['artist'],
                         mode = 'markers', 
                         marker = dict(line = dict(width = 2,
                                                color = 'black'),
                                     symbol = 'star', 
                                     size = 20, 
                                     color = 'gold'),
                         name = 'Best New Artist',
                         hovertemplate = 'Artist: %{y}'+'<br>Date: %{x|%Y-%m-%d} <extra></extra>',
                        ))
    
    
# scatter points for VMA awards
fig.add_trace(go.Scatter(x = filtered_vmas_copy['date'], 
                         y = filtered_vmas_copy['artist'],
                         mode = 'markers', 
                         marker = dict(line = dict(width = 1),
                                     symbol = 'circle', 
                                     size = 10, 
                                     color = 'darkorange'),
                         opacity = 0.9,
                         name = 'VMA Win/Nomination',
                         hovertemplate = 'Artist Name: %{y}'+'<br>Date: %{x|%Y-%m-%d} <extra></extra>'
        
                        ))

# scatter points for AMA awards
fig.add_trace(go.Scatter(x = filtered_amas_copy['date'],
                         y = filtered_amas_copy['artist'],
                         mode = 'markers', 
                         marker = dict(line = dict(width = 1),
                                     symbol = 'circle', 
                                     size = 10, 
                                     color = 'limegreen'),
                         opacity = 0.9,
                         name = 'AMA Win/Nomination',
                         hovertemplate = 'Artist: %{y}'+'<br>Date: %{x|%Y-%m-%d} <extra></extra>'
                        ))

fig.update_layout(width = 800, 
                  height = 600,
                  plot_bgcolor = 'lightgray',
                  title = 'Awards Received by Artists',
                  title_font = dict(size = 20, family = 'Arial, sans serif'),
                  xaxis = dict(title='Date', 
                             title_font = dict(size = 15, family = 'Helvetica, sans-serif'),
                             tickfont = dict(size = 10)),
                  yaxis = dict(title ='Artist',
                             title_font = dict(size = 15, family = 'Helvetica, sans-serif'), 
                             tickfont = dict(size =10), 
                             autorange ="reversed"), 
                  legend = dict(font = dict(size = 10))
                 )

py.iplot(fig)
```

``` {python}
#| label: fig-hot100s_timeline
#| fig-cap: "Timeline of Best New Artist wins and Billboard Hot 100s entries." 
#| warning: false

#------------------------
# START CITATION 
# link/s below were used to help me generate the following code ()

# (creating scatter plot) https://plotly.com/python/line-and-scatter/
# (add multiple traces in one plot) https://stackoverflow.com/questions/72349796/add-a-plotly-express-trace-to-a-graph-objects-go-figure-with-multiple-traces
# (plotly.go parameters) https://plotly.com/python-api-reference/generated/plotly.graph_objects.Scatter.html
# (Hover text) https://stackoverflow.com/questions/59057881/how-to-customize-hover-template-on-with-what-information-to-show
# (removign trace name) https://community.plotly.com/t/how-to-remove-the-trace0-and-trace-1-boxes-when-hovering-over-pie-charts-in-subplot/76302/2
# (date) https://plotly.github.io/plotly.py-docs/generated/plotly.graph_objects.Waterfall.html

import plotly.io as pio

# creating Plotly graph objects figure
fig = go.Figure()

# scatter points for Best New Artist Win
fig.add_trace(go.Scatter(x = best_new_df['award_date'], y = best_new_df['artist'],
                         mode = 'markers', marker = dict(line = dict(width = 2,
                                                                 color = 'black'),
                                                     symbol = 'star', 
                                                     size = 20, 
                                                     color = 'gold'),
                         name = 'Best New Artist Win', 
                         hovertemplate = 'Artist: %{y}'+'<br>Date: %{x} <extra></extra>'))
    
# scatter points for hot 100s df
fig.add_trace(go.Scatter(x = filtered_hot100_copy['chart_week'], 
                         y = filtered_hot100_copy['artist'],
                         mode ='markers', 
                         opacity = 0.7,
                         marker = dict(symbol = 'circle', 
                                     size = 10, 
                                     color = 'purple'),
                         name = 'Charted Song',
                         hovertemplate = 'Artist: %{y}'+'<br>Date: %{x} <extra></extra>'))

fig.update_layout(width = 800, 
                  height = 600, 
                  plot_bgcolor = 'lightgray',
                  title = 'Billboard Hot 100s Charted Songs',
                  title_font = dict(size = 20),
                  xaxis = dict(title = 'Date', 
                               title_font = dict(size = 15, 
                                                 family = 'Helvetica, sans-serif'), 
                               tickfont = dict(size = 10)),
                  yaxis = dict(title = 'Artist',
                               title_font = dict(size = 15, 
                                                 family = 'Helvetica, sans-serif'), 
                               tickfont = dict(size = 10),
                               autorange ="reversed"),
                  legend = dict(font = dict(size = 10))
                 )
py.iplot(fig)

# END CITATION
```

Both timelines yield very similar conclusions that challenged the speculation that winning the Best New Artist award leads to an unsuccessful or inactive careers. @fig-vma_ama displays the award and nomination activity for each artist along with the date they won the Best New Artist Award, which offers us insights inot their post-Grammy recognition. Reviewing both wins and nominations allows us to figure out if these artists continue to be celebrated for their music. While some artists indeed fade away from prominence after their Grammy win (such as Jody Watley, Esperanza Spalding, Macklemore & Ryan Lewis), others contine to receive acclaim (such as Mariah Carey, Alicia Keys, Carrie Underwood, Maroon 5). 

@fig-hot100s_timeline is my personal favorite. From the data I collected, in my opinion the Billboard Hot 100s data is a very good and reliable indicator of how well an artist is doing in the music industry. This chart is a very respectable chart that many artists yearn to appear on [@chart_important]. Being on this chart means that an artist's song is very popular during the week, taking into account its sales, streams, radio play, and online downloads. 

This timeline shows us that a lot of artists had very long and successful careers post-award win. For example Mariah Carey can be seen to have a very long and consistent career after being named the Best New Artist in 1991. This timeline shows us that not every artist’s career deteriorated after winning the Best New Artist Award. Many artists are either still relevant today, as they are still being seen on the charts, or have generally had a long career, such as Toni Braxton and Christina Aguilera. While there are artists who did suffer landing on the charts post win, this may not be the work of the Best New Artist curse, rather it may just be due to coincidence or more personal reasons. This timeline helps prove that this curse is simply just a myth, and that not all of the artists who win the award suffer career decline. 


# Predicting Success
Despite the limitations of a fairly small dataset, I want to attempt to make a model that can predict the success of an artist after winning the Best New Artist Award. Now, you might be wondering, how exactly am I going to predict the success of an artist? Well the answer lies in creating my own unique success metric.

``` {python}
#| output: false
#hot100 songs count:

hot100s_count = filtered_hot100_copy['artist'].value_counts()

hot100s_count_df = pd.DataFrame({'num_on_chart':hot100s_count})

hot100s_count_df = hot100s_count_df.reset_index()
# ----------------------

# START CITATION 
# link/s below were used to help me generate the following code (horizontal bar plot)

# https://www.geeksforgeeks.org/matplotlib-pyplot-barh-function-in-python/

# sorting the hot100s_count in descending order
hot100s_count_sorted = hot100s_count.sort_values(ascending=True)

# Create a horizontal bar chart of the total Hot100s song received by each artist
plt.figure(figsize=(10, 8))
plt.barh(hot100s_count_sorted.index, hot100s_count_sorted, color='mediumvioletred')

plt.title('Total Number of Charted Songs by Artist', 
          fontsize = 20, 
          fontweight = 'bold')

plt.xlabel('Total Number of Songs', 
           fontsize = 15, 
           fontweight = 'bold')

plt.ylabel('Artist', 
           fontsize = 15, 
           fontweight = 'bold')

plt.tight_layout()

# END CITATION

# -----------------------
# START CITATION 

# link/s below were used to help me generate the following code (.groupby() and value counts)

# https://stackoverflow.com/questions/39132742/groupby-value-counts-on-the-dataframe-pandas

#vmas count:

vmas_count = filtered_vmas_copy.groupby(['artist', 'win']).size().unstack(fill_value = 0)

# updating the column headers to reflect whetehr the artist won or lost
vmas_count.columns = ['vmas_lost', 'vma_win']

vmas_count.reset_index()

amas_count = filtered_amas_copy.groupby(['artist', 'win']).size().unstack(fill_value = 0)

# updating the column headers to reflect whetehr the artist won or lost
amas_count.columns = ['amas_lost', 'amas_win']

amas_count.reset_index()

# END CITATION

# reading only the last five columns of the dummy riaa df
last_five_cols = dummy_riaa_df.iloc[:, -5:]

# grouping by artist and adding the values in the last five columns for each artist
riaa_counts = last_five_cols.groupby(dummy_riaa_df['artist']).sum()

# adding columns with the overall total amount of RIAA awards an artist received
riaa_counts['total'] = riaa_counts.sum(axis=1)

# sorting the riaa_counts in descending order
riaa_counts_sorted = riaa_counts.sort_values(by='total', ascending=True)

# START CITATION 
# link/s below were used to help me generate the following code (horizonatal, stacked bar plot)

# https://www.geeksforgeeks.org/matplotlib-pyplot-barh-function-in-python/

# dropping the total column as it is not needed for this dataframe
riaa_counts_sorted = riaa_counts_sorted.drop(columns = 'total')

legend_labels = ['Diamond', 'Gold', 'Multi-Diamond', 'Multi-Platinum', 'Platinum']

plt.figure(figsize=(20, 15))

riaa_counts_sorted.plot(kind='barh', stacked=True)
plt.title('RIAA Awards Received by Artists', fontsize = 45, fontweight = 'bold')
plt.xlabel('Number of Awards', fontsize = 30, fontweight = 'bold')
plt.ylabel('Artist', fontsize = 30, fontweight = 'bold')
plt.xticks(fontsize=25)  # Adjust x-axis tick labels font size
plt.yticks(fontsize=25)
plt.legend(legend_labels, title='Award Type', loc='lower right', title_fontsize = 25, fontsize = 25)
plt.subplots_adjust(right=0.5)  # Increase space on the right side for the legend

plt.tight_layout(rect=[6, 5,10, 10])

```


## Quantifying Success
``` {python}
#| output: false
# Artists excluded due to lack of information
excluded_artists = ['Olivia Rodrigo', 'Megan Thee Stallion', 'Billie Eilish', 'Dua Lipa']
# ---------------------------
# START CITATION 
# link/s below were used to help me generate the following code (.dateoffset)

# https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.html

# Calculating the Billboard Hot 100s Score

# merging 'filtered_hot100_copy' with 'best_new_df' on the 'artist' column
merged_df = pd.merge(filtered_hot100_copy, best_new_df, on='artist', how='inner')

# filtering the singles within five years after the award date
# the chart week date must be in the artist's best new artist win date AND five years after 
# their best new artist win date. 
filtered_df = merged_df[(merged_df['chart_week'] >= merged_df['award_date']) &
                        (merged_df['chart_week'] <= merged_df['award_date'] + pd.DateOffset(years=5))]

# END CITATION
# ----------------------------
# START CITATION 
# link/s below were used to help me generate the following code

# https://pandas.pydata.org/docs/dev/reference/api/pandas.concat.html (concataneting row to df)
# https://www.geeksforgeeks.org/how-to-add-one-row-in-an-existing-pandas-dataframe/ (adding row to df)

# scoring each artist
billboard_scores_df = pd.DataFrame(columns = ['artist', 'billboard_score'])

# score variable 
score = 0 

for index, row in filtered_df.iterrows():
    
    # this if-else statement represents whether the artist was a main artist or not
    if row['main_artist'] == 'yes':
        
        # these if-else statements represents the chart rank position of the song
        if 1 <= row['rank'] <= 20:
            score += 5
        
        elif 21 <= row['rank'] <= 40:
            score += 4
        
        elif 41 <= row['rank'] <= 60:
            score += 3
        
        elif 61 <= row['rank'] <= 80:
            score += 2
        
        else:
            score += 1
            
    # not main artist        
    else:
        score += 1
    
    #adding the score to the df
    if row['artist'] in billboard_scores_df['artist'].values:
        
        billboard_scores_df.loc[billboard_scores_df['artist'] == row['artist'], 'billboard_score'] += score
    
    # adding artist in df if they are not already there, adding score too    
    else:
        new_row = pd.DataFrame({'artist': [row['artist']], 'billboard_score': [score]})
        billboard_scores_df = pd.concat([billboard_scores_df, new_row], ignore_index = True)
        
    # resetting score variable
    score = 0      

# END CITATION 
#----------------------


# merging with the best_new_df to display all the Best New Artists and their respective score
merged_billboard_scores = pd.merge(best_new_df, billboard_scores_df, on = 'artist', how = 'left')

merged_billboard_scores['billboard_score'] = merged_billboard_scores['billboard_score'].fillna(0)

# filling in missing values with 0
merged_billboard_scores['billboard_score'] = merged_billboard_scores['billboard_score'].fillna(0)

# changing billboard score column data type to integer
merged_billboard_scores['billboard_score'] = merged_billboard_scores['billboard_score'].astype('int64')

#----------------------
# START CITATION 
# link/s below were used to help me generate the following code (excluding values in df based on specific conditions)

# https://stackoverflow.com/questions/71142985/exclude-values-in-df-column
# https://stackoverflow.com/questions/55330568/how-to-exclude-rows-based-on-multi-column-value-conditions-in-pandas-dataframe

# creating df without the excluded artists
filter_billboard_scores = merged_billboard_scores[~merged_billboard_scores['artist'].isin(excluded_artists)]

filter_billboard_scores = filter_billboard_scores.reset_index()

filter_billboard_scores = filter_billboard_scores.drop(columns = 'index')
# END CITATION 
# -----------------------

# VMAS Sccore

# merging 'filtered_vmas_copy' with 'best_new_df' on the 'artist' column
merged_vmas = pd.merge(filtered_vmas_copy, best_new_df, on='artist', how='inner')

# --------------------------
# START CITATION 
# link/s below were used to help me generate the following code (.dateoffset)

# https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.html

# filtering the singles within five years after the award date
five_yr_vmas = merged_vmas[(merged_vmas['date'] >= merged_vmas['award_date']) &
                        (merged_vmas['date'] <= merged_vmas['award_date'] + pd.DateOffset(years=5))]
# END CITATION
# ---------------------------

# checking to see if any artists are condiered featured artists in the df
five_yr_vmas['featured_artist'].unique()

# START CITATION 
# link/s below were used to help me generate the following code

# https://stackoverflow.com/questions/39132742/groupby-value-counts-on-the-dataframe-pandas (groupby value counts)

# counting the number of wins and losses
vmas_count = five_yr_vmas.groupby(['artist', 'win']).size().unstack(fill_value = 0)
# END CITATION
# --------------------

# renaming headers
vmas_count.columns = ['vmas_lost', 'vmas_win']

vmas_count.reset_index()

# merging the count with the best_new_df
counts_vmas_merge = pd.merge(best_new_df, vmas_count, on = 'artist', how = 'left')

# changing data types anf filling in missing values 
counts_vmas_merge['vmas_lost'] = counts_vmas_merge['vmas_lost'].fillna(0).astype('int64')

counts_vmas_merge['vmas_win'] = counts_vmas_merge['vmas_win'].fillna(0).astype('int64')

# START CITATION 
# link/s below were used to help me generate the following code (excluding values in df based on specific conditions)

# https://stackoverflow.com/questions/71142985/exclude-values-in-df-column
# https://stackoverflow.com/questions/55330568/how-to-exclude-rows-based-on-multi-column-value-conditions-in-pandas-dataframe


# creating df without the excluded artists
filter_vmas_five = counts_vmas_merge[~counts_vmas_merge['artist'].isin(excluded_artists)]

filter_vmas_five = filter_vmas_five.reset_index()

filter_vmas_five = filter_vmas_five.drop(columns = 'index')

filter_vmas_five['vmas_lost'] = filter_vmas_five['vmas_lost']

filter_vmas_five['vmas_win'] = filter_vmas_five['vmas_win']
# END CITATION
# _________________

# finding overall score
vmas_score_list = []

for index, row in filter_vmas_five.iterrows():
    
    artist_score = (row['vmas_lost'] * 2) + (row['vmas_win'] * 5)
    vmas_score_list.append(artist_score)
    
    
filter_vmas_five['vmas_score'] = vmas_score_list

# AMAS Score

# merging 'filtered_amas_copy' with 'best_new_df' on the 'artist' column
merged_amas = pd.merge(filtered_amas_copy, best_new_df, on='artist', how='inner')

# START CITATION 
# link/s below were used to help me generate the following code (.dateoffset)

# https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.html

# filtering the singles within five years after the award date
five_yr_amas = merged_amas[(merged_amas['date'] >= merged_amas['award_date']) &
                        (merged_amas['date'] <= merged_amas['award_date'] + pd.DateOffset(years=5))]

# END CITATION
# -------------------------
# START CITATION 
# link/s below were used to help me generate the following code (groupby, value counts)

# https://stackoverflow.com/questions/39132742/groupby-value-counts-on-the-dataframe-pandas

# counting wins and losses
amas_count = five_yr_amas.groupby(['artist', 'win']).size().unstack(fill_value = 0)

amas_count.columns = ['amas_lost', 'amas_win']

# END CITATION
# -------------------------

# merging the best_new df with the wins/losses count df 
counts_amas_five = pd.merge(best_new_df, amas_count, on = 'artist', how = 'left')

# filled in missing values with zero
counts_amas_five['amas_lost'] = counts_amas_five['amas_lost'].fillna(0)
counts_amas_five['amas_win'] = counts_amas_five['amas_win'].fillna(0)

# ----------------------------
# START CITATION 
# link/s below were used to help me generate the following code (excluding values in df based on specific conditions)

# https://stackoverflow.com/questions/71142985/exclude-values-in-df-column
# https://stackoverflow.com/questions/55330568/how-to-exclude-rows-based-on-multi-column-value-conditions-in-pandas-dataframe
# creating df without the excluded artists
filter_amas_five = counts_amas_five[~counts_amas_five['artist'].isin(excluded_artists)]

# END CITATION 
# -----------------

filter_amas_five = filter_amas_five.reset_index()

filter_amas_five = filter_amas_five.drop(columns = 'index')

# adjusting data types
filter_amas_five['amas_lost'] = filter_amas_five['amas_lost'].astype('int64')
filter_amas_five['amas_win'] = filter_amas_five['amas_win'].astype('int64')

# totaling up the score

amas_score_list = []

for index, row in filter_amas_five.iterrows():
    artist_score = (row['amas_lost'] * 2) + (row['amas_win'] * 5)
    amas_score_list.append(artist_score)
    
    
filter_amas_five['amas_score'] = amas_score_list

# RIAA Score

# merging 'dummy_riaa_df' with 'best_new_df' on the 'artist' column
merged_riaa = pd.merge(dummy_riaa_df, best_new_df, on='artist', how='inner', suffixes = ('_riaa', '_bestnew'))

# ------------------------
# START CITATION 
# link/s below were used to help me generate the following code (.dateoffset)

# https://pandas.pydata.org/docs/reference/api/pandas.tseries.offsets.DateOffset.html

# filtering the songs within five years after the award date
five_yr_riaa = merged_riaa[(merged_riaa['award_date_riaa'] >= merged_riaa['award_date_bestnew']) &
                        (merged_riaa['award_date_riaa'] <= merged_riaa['award_date_bestnew'] + pd.DateOffset(years=5))]

# END CITATION
# ------------------

# reading the last five columns of the dummy riaa df
last_five_cols = dummy_riaa_df.iloc[:, -5:]

# grouping by artist and adding the values in the last five columns for each artist
riaa_counts = last_five_cols.groupby(five_yr_riaa['artist']).sum()       

# merging the best_new df and RIAA counts 
counts_riaa_five = pd.merge(best_new_df, riaa_counts, on = 'artist', how = 'left')

# renaming columns and filling in missing values with 0

columns = ['diamond', 'gold', 'multi_diamond', 'multi_platinum', 'platinum']

# START CITATION 
# link/s below were used to help me generate the following code: (filling in missing values)

# https://stackoverflow.com/questions/36556256/how-do-i-fill-na-values-in-multiple-columns-in-pandas 

counts_riaa_five[columns] = counts_riaa_five[columns].fillna(0)

# END CITATION
# -------------------

# adjusting data type
counts_riaa_five[columns] = counts_riaa_five[columns].astype('int64')

# -------------------
# START CITATION 
# link/s below were used to help me generate the following code (excluding values in df based on specific conditions)

# https://stackoverflow.com/questions/71142985/exclude-values-in-df-column
# https://stackoverflow.com/questions/55330568/how-to-exclude-rows-based-on-multi-column-value-conditions-in-pandas-dataframe

# making new df without the excluded artists
filter_riaa_five = counts_riaa_five[~counts_riaa_five['artist'].isin(excluded_artists)]

filter_riaa_five = filter_riaa_five.reset_index()

filter_riaa_five = filter_riaa_five.drop(columns = 'index')
# END CITATION
# ----------------------
# totaling the RIAA total score
riaa_score_list = []

for index, row in filter_riaa_five.iterrows():
    artist_score = (row['diamond'] * 4) + (row['gold'] * 1) + (row['multi_diamond'] * 5) + (row['multi_platinum'] * 3) + (row['platinum'] * 2)
    riaa_score_list.append(artist_score)
    
    
filter_riaa_five['riaa_score'] = riaa_score_list

# merging and creating score df

# merging the vmas and amas filtered df 
merge_1 = pd.merge(filter_vmas_five, filter_amas_five, on = 'artist')

# dropping unnecessary columns
merge_1 = merge_1.drop(columns = ['award_date_x', 
                                  'vmas_lost', 
                                  'vmas_win', 
                                  'award_date_y', 
                                  'amas_lost', 
                                  'amas_win'])

# adding the RIAA filtered df to the merged df                                 
merge_2 = pd.merge(merge_1, filter_riaa_five, on = 'artist')

# dropping unnecessary columns
merge_2 = merge_2.drop(columns = ['award_date', 
                                        'diamond', 
                                        'gold', 
                                        'multi_diamond', 
                                        'multi_platinum', 
                                        'platinum'])

# merging the billboard filtered df to the merged df
all_scores = pd.merge(merge_2, filter_billboard_scores, on = 'artist')
all_scores = all_scores.drop(columns = 'award_date')

# Normalizing the scores 

# copying the df
all_scores_2 = all_scores

# I will be using the min-max normlization technique
#finding min and max of vmas_score

vmas_min = all_scores_2['vmas_score'].min()
vmas_max = all_scores_2['vmas_score'].max()

# new df
all_scores_scaled = all_scores_2

# normalizing the vmas column
all_scores_scaled['vmas_score'] = (all_scores_scaled['vmas_score'] - vmas_min)/(vmas_max - vmas_min)

# min and max of amas
amas_min = all_scores_2['amas_score'].min()
amas_max = all_scores_2['amas_score'].max()

# normalizing the amas column
all_scores_scaled['amas_score'] = (all_scores_scaled['amas_score'] - amas_min)/(amas_max - amas_min)

# min and max of riaa
riaa_min = all_scores_2['riaa_score'].min()
riaa_max = all_scores_2['riaa_score'].max()

# normalizing the riaa column
all_scores_scaled['riaa_score'] = (all_scores_scaled['riaa_score'] - riaa_min)/(riaa_max - riaa_min)

# min and max of billboard
billboard_min = all_scores_2['billboard_score'].min()
billboard_max = all_scores_2['billboard_score'].max()

# normalizing the billboard column
all_scores_scaled['billboard_score'] = (all_scores_scaled['billboard_score'] - billboard_min)/(billboard_max - billboard_min)

# creating total scores column

all_scores_scaled['total_score'] = all_scores_scaled['vmas_score'] + all_scores_scaled['amas_score'] + all_scores_scaled['riaa_score'] + all_scores_scaled['billboard_score']

```

For this project, I decided to base the success of the artist based on these four factors: the number of Billboard Charted songs, RIAA awards, AMAS/VMAS awards and nominations.

In order to take into consideration the fact that older artists may have more activity compared to newer winners, I will only be focusing on each artist’s accomplishments within the five years after they won the Best New Artist award. So in this case the artists from 2019 and on will not be included. 

Here is how I will be scoring the artists:

Billboard single: If chart position is

- 1 - 20: 5 points per song
- 21 - 40: 4 points per song
- 41 - 60: 3 points per song
- 61 - 80: 2 points per song
- 81 - 100: 1 point per song
- featured artist: 1 point per song

RIAA Awards:

- Multi-Diamond: 5 points
- Diamond: 4 points
- Multi-Platinum: 3 points
- Platinum: 2 points
- Gold: 1 points

American Music Awards/MTV Video Music Awards:

- Win: 5 points
- Nomination: 2 points

After calculating the scores for each artist based on each feature, I noticed that some features had a much wider range of values than the others. To make sure all features contributed equally to the final score, I used a method called min-max normalization. This technique scales all scores to fit within the same range. Once the scores were normalized, I added them together to calculate each artist’s total success score. 

``` {python}
#| output: false
# creating df to be used for modeling
# predictors: gender, music group, genre
# target: total success score

# best new artist df with the artists from 2019 and on excluded
best_new_filtered = best_new_df.iloc[:-4].reset_index()
best_new_filtered = best_new_filtered.drop(columns = 'index')

#  merginf best new and artist_info_df 

modeling_merge_1 = pd.merge(best_new_filtered, artist_info_df[['artist','gender', 'music_group']], on = 'artist', how = 'left')

# merging artist genre
modeling_merge_2 = pd.merge(modeling_merge_1, artist_genres_df, on = 'artist', how = 'left')

# merging the total score to the scaled score df
all_scores_scaled_subset = all_scores_scaled[['artist', 'total_score']]
final_modeling_merge = pd.merge(modeling_merge_2, all_scores_scaled_subset, on = 'artist', how = 'left')

# getting dummy variables for the 'genre' column
genre_dummies = final_modeling_merge['genre'].str.get_dummies(sep = ',')

genre_dummies.columns = genre_dummies.columns.str.strip()

genre_dummies.columns = genre_dummies.columns.str.replace('"', '')

# concatenating the dummy genre columns with the original df
final_modeling_merge = pd.concat([final_modeling_merge, genre_dummies], axis=1)

# dropping the original 'genre' column
final_modeling_merge.drop(columns=['genre'], inplace=True)

# dropping total score for now while I get dummy variables for the other columns

# creating new df
modeling_df_enc = final_modeling_merge.drop(columns = ['artist','award_date'])

modeling_df_enc = pd.get_dummies(modeling_df_enc).astype(int)

modeling_df_enc = modeling_df_enc.drop(columns = 'total_score')

# stripping the df for apostrophes
modeling_df_enc.columns = modeling_df_enc.columns.str.strip('"')

# adding back total score column, renaming to success score
modeling_df_enc['success_score'] = final_modeling_merge['total_score']

# checking for missing values
modeling_df_enc.isna().sum().sum()

# replacing any spaces in the header to underscores
modeling_df_enc.columns = modeling_df_enc.columns.str.replace(' ', '_')
```

To predict the scores I tested three regression models. After combining the necessary information, I checked for multicollinearity between the predictors I will be using: music genres, artist gender, and membership in music groups. Multicollinearity occurs when predictors are very correlated with each other, which can affect the reliability of a model’s predictions. I found that there was high multicollinearity throughout the dataset, especially between the gender and music group features. However, due to the limited amount of predictors and observations being used, I will be keeping all of the predictors for the modeling portion of this project. Therefore please be aware that the model's coefficients may not be reliably interpretable.

I will create and compare the following regression models: Linear Regression, Support Vector Regression, and Decision Tree Regressor. 

## Modeling Performance
``` {python}
#| output: false
#| warning: false
# predictors

# START CITATION

# Linear Regression Resources:
    # https://realpython.com/linear-regression-in-python/
    # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html

# Support Vector Regression Resources:
    # https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html 
    # Machine Learning Class, utilized the svm code that was taught and tweaked it to work with svr
    
# Decision Tree Regressor Resources:
    # https://www.geeksforgeeks.org/python-decision-tree-regression-using-sklearn/
    # https://medium.com/@theclickreader/decision-tree-regression-explained-with-implementation-in-python-1e6e48aa7a47
      
# MSE, MAE, R^2 Resource:
    # MSE: From Machine Learning Class
    # MAE = https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html
    # R^2 = https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html

# Cross Validation Resource:
    # https://www.w3schools.com/python/python_ml_cross_validation.asp
    
# pd.Dataframe():
    # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html
    
# Correlation Matrix:
    # https://stackoverflow.com/questions/65988614/visualizing-a-huge-correlation-matrix-in-python


x = modeling_df_enc.drop(columns = ["success_score"],axis=1)
# target variable
y = modeling_df_enc['success_score']

# Correlation Matrix to check for multicollinearity
plt.figure(figsize=(10, 8))
sns.heatmap(x.corr(), cmap='coolwarm', fmt=".2f")

# standarizing the predictor values
sc = StandardScaler()
X = sc.fit_transform(x)

#70/30 train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 42, test_size=0.30)
```

``` {python}

#| echo : true

# Linear Regression 
# creating linear regression model
linear_model = LinearRegression()

# fitting the model
linear_model.fit(X_train, y_train)
linear_model

# predicting 
y_pred = linear_model.predict(X_test)
y_pred


# evaluating performance
mse = round(mean_squared_error(y_test, y_pred), 3)
mae = round(mean_absolute_error(y_test, y_pred), 3)
r2 = round(r2_score(y_test, y_pred), 3)

# adding performance scores to a df
perform_list = [mse, mae, r2]

linear_results_df = pd.DataFrame(perform_list, columns = ['Linear Regression'], index = ['Mean Squared Error', 'Mean Average Error', 'R-squared'])


# creating the SVR classifier
svr_reg = Pipeline([
        ("scaler", StandardScaler()),
        ("svr", SVR(kernel = 'linear', C = 1)),
    ])

# fitting the SVR classifier
svr_reg.fit(X_train, y_train)

# predicting
y_pred_svr = svr_reg.predict(X_test)

# calculating evaluation metrics
mse_svr = round(mean_squared_error(y_test, y_pred_svr), 3)
mae_svr = round(mean_absolute_error(y_test, y_pred_svr), 3)
r2_svr = round(r2_score(y_test, y_pred_svr), 3)

# adding performance scores to a df
perform_list = [mse_svr, mae_svr, r2_svr]

svr_results_df = pd.DataFrame(perform_list, columns = ['Support Vector Regression'], index = ['Mean Squared Error', 'Mean Average Error', 'R-squared'])


# Decision Tree
# creating the regressor
tree_reg = DecisionTreeRegressor(random_state = 42, max_depth = 5)

# fitting the dt to the trainign data
tree_reg.fit(X_train, y_train)

# predicting the target values of the test
y_pred_tree = tree_reg.predict(X_test)

# calculating evaluation metrics
mse_tree = round(mean_squared_error(y_test, y_pred_tree), 3)
mae_tree = round(mean_absolute_error(y_test, y_pred_tree), 3)
r2_tree = round(r2_score(y_test, y_pred_tree), 3)

# adding performance scores to a df
perform_list = [mse_tree, mae_tree, r2_tree]

tree_results_df = pd.DataFrame(perform_list, columns = ['Decision Tree Regressor'], index = ['Mean Squared Error', 'Mean Average Error', 'R-squared'])


# combining the model performances into one df

# joining the linear and svr results df
combine_performance = linear_results_df.join(svr_results_df)

# adding tree
combine_performance = combine_performance.join(tree_results_df)

# final joined df
combine_performance
```

:::{.callout-tip}
## Tip: Mean Squared What?

Here is a quick lesson on the metrics to evaluate a regression model. 

- Mean squared error (MSE): This metric finds the difference between the actual/true values of data points and the predicted values. The lower the MSE score, the better the model's performance is.   

- Mean Average Error (MAE): This metric calculates the average of all of the differences between the actual/true values and the predicted values. Similar to the MSE metric, the lower the score, the better the model's performance is. 

- R squared: This metric describes the proportion of variance in the model and how strong the relationship is between the independent and the dependent variables. For this metric, a higher score indicates better model performance. 
:::

After evaluating the performance of each regression model, it is safe to say that the Decision Tree Regressor model outperforms the others. This conclusion is supported by its relatively low Mean Squared Error (MSE) and Mean Absolute Error (MAE) values, suggesting a better predictive accuracy compared to the other models. Furthermore, the Decision Tree Regressor has the highest R-squared value, indicating that it explains a greater proportion of the variance in the target variable. 

However, it is important to recognize that while this model demonstrates the best performance among the models tested, its performance is not that exceptional. This is most likely due to the limited size and simplicity of the data, which provides a constrained number of observations and features. It is reasonable to infer that more data would further strengthen the model's predictive capabilities.

## Features Impacting Success

Utilizing the Decision Tree Regressor, I went ahead and found the top five features that have a significant impact on an artist's success following their award win.

``` {python }

#| echo : true 

# finding the features that are the most significant in the decison tree's predictions
dt_feature_importance = pd.Series(tree_reg.feature_importances_, index = x.columns)

top_5_dt = dt_feature_importance.nlargest(5)

top_5_df = pd.DataFrame(top_5_dt).reset_index()

top_5_df.columns = ['feature', 'importance_score']

top_5_df['feature'] = top_5_df['feature'].str.replace('_', ' ')

top_5_df
```

Here we can see that dance pop, r&b, country dawn, uk pop, and country are the top five features that have the most significant impact to an artist's success based on the Decision Tree model. 

# Conclusions

## Limitations

The biggest limiation I faced while working on this project was lack of data. Not only was I working with a small set of artists, but I was very limited to what data I can collect for these artists. Some information I wanted to, but could not, collect are: number of concerts/tours each artist performed, and mentions in social media. 

Furthermore, success is not only about the numbers and the amount of awards and recognition an artist recieves throughout the years. My project lacks the ability to take into action the more impactful ways artist's have made their marks on the music industry. Success is a very subjective topic, so at the end of the day, an artist may be seen as more successful and impactful than others by certain people. 

It is also worth noting that some celebrities dissappear from the music industry due to personal factors, such as: retirement, scandals, death, etc..

## Final Thoughts

This project was very enjoyable to work on as it allowed me to mix my own personal passions and curiousities with my knowledge in Data Science. I believe this curse is simply a myth, it does not exist. Based on the visuals presented in this project, there are many artists who continue to grow their careers after winning the Best New Artist Award.

In the future, I would love to expand on my findings and dive deeper into the reason why certain artists become more successful than others. To add more observations, I would like to compare the success of the Grammy Best New Artist's to equivalent Best New Artist award's in other music award shows. Furthermore, I am looking to also utilize my models to create a program that will allow one to input features an artist possesses in order to predict their success score.